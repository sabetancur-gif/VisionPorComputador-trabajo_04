# VisiÃ³n por Computador: QuantumViz

## ğŸ§  Trabajo 04 â€” Sistema de DetecciÃ³n y Seguimiento de Objetos en Video

---

### ğŸ“Œ Resumen

Este repositorio documenta, implementa y evalÃºa un pipeline completo para la detecciÃ³n de objetos mediante YOLO y seguimiento de objetos mediante tÃ©cnicas de flujo Ã³ptico, aplicada a un problema prÃ¡ctico.

El objetivo es desarrollar una aplicaciÃ³n de visiÃ³n por computador que integre detecciÃ³n de objetos mediante YOLO y seguimiento de objetos mediante tÃ©cnicas de flujo Ã³ptico, aplicada a un problema prÃ¡ctico utilizando datos de video disponibles pÃºblicamente.

---

### ğŸ“ Estructura del repositorio

```
proyecto-clasificacion-imagenes-medicas/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ 5a0affad-23d2-11e8-a6a3-ec086b02610b
â”‚   â”‚   â”‚   â””â”€â”€ 5a0affad-23d2-11e8-a6a3-ec086b02610b
â”‚   â”‚   â”œâ”€â”€ cis_test_annotations.json
â”‚   â”‚   â”œâ”€â”€ cis_val_annotations.json
â”‚   â”‚   â”œâ”€â”€ train_annotations.json
â”‚   â”‚   â”œâ”€â”€ trans_val_annotations.json
â”‚   â”‚   â””â”€â”€ fauna.mp4
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratorio.ipynb
â”œâ”€â”€ resultados/
â”‚   â””â”€â”€ cis_val_run/
â”‚   â”‚   â”œâ”€â”€ detection_metrics.json
â”‚   â”‚   â”œâ”€â”€ detection.csv
â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â”œâ”€â”€ tracks.csv
â”‚   â”œâ”€â”€ fauna_frame_summary.csv
â”‚   â””â”€â”€ fauna_recognized.mp4
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ detector.py
â”‚   â”œâ”€â”€ eval.py
â”‚   â”œâ”€â”€ fauna.py
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â”œâ”€â”€ tracker.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md   # <- este archivo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_pipeline.sh
â””â”€â”€ yolo8n.pt
```

---

### ğŸ¯ Objetivos especÃ­ficos

* Implementar y configurar un modelo de detecciÃ³n de objetos YOLO (v5, v8 u otra versiÃ³n).
* Aplicar tÃ©cnicas de flujo Ã³ptico (Lucas-Kanade o flujo denso) para el seguimiento de objetos entre fotogramas.
* Integrar ambas tÃ©cnicas en un pipeline coherente de anÃ¡lisis de video.
* Evaluar cuantitativamente el desempeÃ±o del sistema.
* Comunicar resultados tÃ©cnicos de forma clara y profesional.

---

### ğŸ“¦ Datos

* El dataset base tanto las imagenes como los metadatos proviene de un conjunto pÃºblico de `https://lila.science/datasets/caltech-camera-traps`, mÃ¡s precisamente de `Benchmark images(6GB)` y `Metadata files for train/val/cis/trans splits (3MB)`


**Nota:** mantener `5a0affad-23d2-11e8-a6a3-ec086b02610b` (u otros ejemplos) en `data/` para pruebas rÃ¡pidas.

---

### ğŸ›  InstalaciÃ³n y entorno

Se recomienda usar un entorno virtual (conda o venv). A continuaciÃ³n instrucciones con `venv` (Windows / Linux / macOS).

```bash
python -m venv venv
# Windows (PowerShell)
# .\venv\Scripts\Activate.ps1
# Linux / macOS
source venv/bin/activate
pip install -r requirements.txt
```

`requirements.txt` incluye (ejemplos): `numpy, pandas, scikit-learn, matplotlib, opencv-python, scikit-image, torch, torchvision, tqdm`.

---

### ğŸš€ EjecuciÃ³n â€” Notebooks (recomendado)

Abrir `run_pipeline.py`o desde la raÃ­z del proyecto y ejecutar desde la terminar el siguiente comando:
``` 
 python -m src.run_pipeline --images data/sample/images --annotations data/sample/cis_val_annotations.json --out results/cis_val_run --detector yolov8n.pt --device cpu --n 200
```

**Nota:** El archivo `notebooks/exploratorio.ipynb` es el Ãºnico .ipynb ejecutable que nos permite realizar un primer acercamiento realizando resultados vistos a lo largo del curso sobre la data.

---

### ğŸ§­ Uso desde Python â€” API mÃ­nima

Ejemplos de import desde `src`:

```python
from src.detector import YOLODetector
from src.tracker import OpticalFlowTracker
from src.eval import detection_metrics
from src.utils import to_int_bbox
from src.data_loader import get_image_list_from_json, load_annotations
```
---
